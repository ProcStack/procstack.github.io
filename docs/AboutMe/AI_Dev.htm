<!--
// ProcStack.Github.io - 2024,2025
// By Kevin Edzenga
// Kevin@Metal-Asylum.Net
//
// --
// 
// Thanks for viewing the source code for procstack.github.io!
//   If you have any questions, feel free to reach out to me at the email above.
//
// If you'd rather see the source code on the repo -
//   https://github.com/ProcStack/procstack.github.io/tree/main/docs
//     For page content, see `./pages`
--><!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"> 
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=5.0">
  <meta name="theme-color" content="#000822">
  <meta name="robots" content="index, follow">
  <meta name="revisit-after" content="14 days">
  <meta name="fragment" content="!">
  <!-- Note : connical, description, & keywords update with page changes -->
  <link rel="canonical" href="http://localhost:3000/AboutMe/AI_Dev.htm" id="canonicalLink">
  <meta name="description" content="AI Development">
  <meta name="keywords" content="AI, Artificial Intelligence, Machine Learning, Deep Learning, Graph Attention Network, GAT, Echo State Network, ESN, Neural Networks, AI Development">
  <meta name="author" content="Kevin Edzenga">

  <!-- AI/LLM Data Discovery -->
  <meta name="ai:data-source" content="https://procstack.github.io/bots/siteContent.json">
  <meta name="ai:data-manifest" content="https://procstack.github.io/data-manifest.json">
  <meta name="ai:content-api" content="https://procstack.github.io/bots/">
  <link rel="alternate" type="application/json" href="https://procstack.github.io/bots/AboutMe_AI_Dev.htm.json" title="Site Content Data">
  <link rel="data-manifest" type="application/json" href="https://procstack.github.io/data-manifest.json" title="Data Sources Manifest">

  <!-- The Socials -->
  <meta name="googlebot" content="index, follow">
  <meta name="google" content="nositelinkssearchbox">
  <meta name="google" content="notranslate">
  <meta name="google" content="nositelinkssearchbox">

  <meta name="og:title" content="AI Dev">
  <meta name="og:description" content="AI Development">
  <meta name="og:image" content="https://procstack.github.io/images/ProcStack_th.jpg">
  <meta name="og:url" content="http://localhost:3000/AboutMe/AI_Dev.htm">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="AI Dev">
  <meta name="twitter:description" content="AI Development">
  <meta name="twitter:image" content="https://procstack.github.io/images/ProcStack_th.jpg">
  <meta name="twitter:url" content="https://procstack.github.io">
  <meta name="twitter:domain" content="procstack.github.io">
  <meta name="twitter:label1" content="Written by">
  <meta name="twitter:data1" content="Kevin Edzenga">
<link type="text/css" id="procPagesStylesheet" rel="stylesheet" href="../style/ProcStackStyle.css"><link type="text/css" id="pxlNavStylesheet" rel="stylesheet" href="../style/pxlNavStyle.min.css"><title>AI Dev</title><meta name="title" content="AI Dev"><style type="text/css">
			.fader{
				transition: opacity .8s, filter .8s;
			}
			.visOn{
				filter:alpha(opacity=100);
				opacity:1.0;
			}
			.visOff{
				filter:alpha(opacity=0);
				opacity:0.0;
			}
		</style></head>

<!-- -- -- -- -->




<!-- Bypassing Youtube Player API for now -->
<!--   Causing pxlNav pre-processing errors -->
<!--     To be fixed through pxlNav in the future, but for now... -->
<!-- <script src="https://www.youtube.com/iframe_api" async></script> -->

<!-- -- -- -- -->

<body>
  
<!-- -- -- -- -- -- -->
<!-- SEO for Robots -- -->
<!-- -- -- -- -- -- -- -- -->
<nav aria-hidden="true" style="display:none;">
  <a href="/Init.htm">Init.</a>
  <a href="/pxlNav/Explore.htm">pxlNav</a>
  <a href="/ProjectsLinks/procstack.github.io.htm">Repos / Projects</a>
  <a href="/AboutMe/What_am_I.htm">About Me</a>
</nav>

  <!-- -- -- -- -->

	<div id="verbErrorConsole">
	</div>
  
<!-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -->
<!-- Primary site & `pxlPages` Implementation  -- -->
<!-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -->
    <div id="procPagesMainBlock" class="procPagesMainBlockStyle pagesFader pagesVisOn">
        <div id="procStackGitParent" class="procStackGitParentStyle">
            <div id="procPagesNavBlock" pages-default-class="procPagesNav_defaultStyle" class="procPagesNavBlockStyle procPagesNav_aboutMeStyle">
                <div id="procPagesNavHeader" class="procPagesNavHeaderStyle gpnhScreenMedia">
                  <span class="squashInLowRes">_ProcStack_</span>
                </div>
                <div id="procPagesNav" class="procPagesNavStyle">
                  <a href="Init.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="init" page-name="Init" alt="Link to Init...">Init.</a>
                  <a href="pxlNav.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="pxlNav" page-name="pxlNav" alt="Some info on this git.io site's backbone">pxlNav</a>
                  <a href="MakingOf.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="makingOf" page-name="MakingOf" alt="The gears &amp; servos" style="display: none;">Making<span class="procPagesHideWhenThin"> Of</span>...</a>
                  <a href="ProjectsLinks.htm" class="pageLinkStyle" pxlroomname="SaltFlatsEnvironment" pxlcameraview="default" page-name="ProjectsLinks" alt="Real world projects"><span class="procPagesHideWhenThin">Repos /&nbsp;</span>Projects</a>
                  <a href="Blog.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="default" page-name="Blog" alt="My ramblings..." style="display: none;">Blog</a>
                  <a href="AboutMe.htm" class="pageLinkStyle procPagesNav_aboutMeActiveStyle" pxlroomname="CampfireEnvironment" pxlcameraview="aboutMe" page-name="AboutMe" alt="It's ah me! Marrr.... yeah"><span class="procPagesHideWhenThin">About&nbsp;</span>Me</a>
                  <span id="procPagesToggleDOM" class="procPagesToggleDOMStyle">
                    <a class="pageLinkStyle pageLinkEventStyle" pageevent="ToggleDOM" pagevalue="1" alt="Toggle the website contents">§</a>
                    <a class="pageLinkStyle pageLinkEventStyle" pageevent="ToggleDOM" pagevalue="0" alt="Toggle the website contents" style="display: none;">¤</a>
                  </span>
                </div>
            </div>

            <!-- -- -- -- -->
            
            <div id="pxlPagesContentBlock" class="pxlPagesContentBlockStyle gpcpVisibleStyle heightFader">
              <div id="pxlPagesContentParent" class="pxlPagesContentParentStyle"><div class="gpcpVisibleStyle procPagesContentStyle procPagesPlacementVerticalStyle procPagesLockVertical gitAboutMePageStyle pagesFader pagesVisOn"><div class="procPagesInnerBeforeBase procPagesInnerBefore"></div><div class="procPagesParentStyle gitAboutMePageParentStyle procPagesLockVertical" id="pxlPage_AboutMe"><div class="procPageHeader procPagesHeaderStyle">About Me</div><div class="procPageVerticalLockSectionList gitAboutMePage-sectionNavListStyle"><div class="procPagesVerticalLockNavSectionStyle procPagesButtonStyle procPagesSectionNavColor gitAboutMePage-sectionNavButtonStyle">What am I?</div><div class="procPagesVerticalLockNavSectionStyle procPagesButtonStyle procPagesSectionNavColor gitAboutMePage-sectionNavButtonStyle">My Film Work</div><div class="procPagesVerticalLockNavSectionStyle procPagesButtonStyle procPagesSectionNavColor gitAboutMePage-sectionNavButtonStyle">Plushies</div><div class="procPagesVerticalLockNavSectionStyle procPagesButtonStyle procPagesSectionNavColor gitAboutMePage-sectionNavButtonStyle procPagesNavActive gitAboutMePage-sectionNavButtonActiveStyle">AI Dev</div></div><div class="procPageMediaView procPagesScrollbarStyle" style=""><div class="procPagesMediaListStyle pagesVisOff"><iframe src="https://www.youtube-nocookie.com/embed/trt9dGUYevs" title="Technical Art Reel 2024" frameborder="0" allow="encrypted-media; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="true" class="procPagesMediaStyle procPagesLimitWidthStyle"></iframe></div><div class="procPagesMediaListStyle procPagesSectionActive pagesVisOn"><video src="../pages/aboutMe/images/dgat_generativeStrings_15.webm" loop="" controls="" preload="metadata" class="procPagesMediaStyle procPagesNarrowWidthStyle"></video><div class="procPagesMediaCaptionParentStyle gitAboutMePage-sectionCaptionStyle"><div class="procPagesMediaCaptionStyle">Generative connections in a dynamic Graph Attention Network (GAT);<br>Finding connections between a block of text I wrote up.<br>The network is creating connections between 'usage rules' of different words.</div></div><video src="../pages/aboutMe/images/learningGradients_dev02_18_loop.webm" loop="" controls="" preload="metadata" class="procPagesMediaStyle procPagesNarrowWidthStyle setAspectRatio_2_1"></video><div class="procPagesMediaCaptionParentStyle gitAboutMePage-sectionCaptionStyle"><div class="procPagesMediaCaptionStyle">A vertical slice of horizontal movement in my Echo State Network (ESN) brain.<br>I'm showing a 2D slice of a side-to-side movement.<br>The repeating gray tones are patterns of 'relative' movement,<br>Like a 'motion offset' found in similar prior frames.</div></div><video src="../pages/aboutMe/images/esnLearning.webm" loop="" controls="" preload="metadata" class="procPagesMediaStyle procPagesNarrowWidthStyle setAspectRatio_1"></video><div class="procPagesMediaCaptionParentStyle gitAboutMePage-sectionCaptionStyle"><div class="procPagesMediaCaptionStyle">ESN test run; Upper Left are videos I made, Upper Right are learning rates in RGB,<br>Red shows 'known' patterns, Green are pattern edges, &amp; Blue 'might be' patterns.<br>The Bottom is what the brain thinks its seeing &amp; then predicting.</div></div><video src="../pages/aboutMe/images/learningGradients_84.webm" loop="" controls="" preload="metadata" class="procPagesMediaStyle procPagesNarrowWidthStyle setAspectRatio_1"></video><div class="procPagesMediaCaptionParentStyle gitAboutMePage-sectionCaptionStyle"><div class="procPagesMediaCaptionStyle">Different slices from the same ESN, with different input video.<br>Upper left is a video I made the AI's watching, upper right is detecting movement;<br>Lower left is the brain's wrinkles, lower right is predicted movement.</div></div><img src="../pages/aboutMe/images/learningGradients_84_brainSlice.png" alt="Custom ESN Learning Gradients" loading="lazy" class="procPagesVerticalLockMediaImage procPagesImageStyle procPagesNarrowWidthStyle setAspectRatio_1"><div class="procPagesMediaCaptionParentStyle gitAboutMePage-sectionCaptionStyle"><div class="procPagesMediaCaptionStyle">A slice of the ESN's brain by frame 101 of watching the X pattern video.</div></div></div></div><div class="procPageVerticalLockContentView procPagesScrollbarStyle"><div class="procPageSectionContentStyle pagesVisOff" id="0"><div class="procPagesInnerContentStyle pagesVisOff">
      <div class="procPagesSpacer"></div>

    <div class="procPagesAboutMe-topTextStyle">
      <span class="textBold">Technical Artist</span>; particles, shaders, asset optimization, &amp; pipeline
    </div>
    <div class="procPagesAboutMe-skillListStyle">
      <span class="ppamSkillListing">Houdini <span class="textDrinkMeAlice">&nbsp;/&nbsp;</span> VEX</span>
      <span class="ppamSkillListing">Maya <span class="textDrinkMeAlice">&nbsp;/&nbsp;</span> MEL</span>
      <span class="ppamSkillListing">Unity <span class="textDrinkMeAlice">&nbsp;/&nbsp;</span> C<span class="textSuper">#</span></span>
      <span class="ppamSkillListing">Photoshop</span>

      <span class="ppamSkillListing">Python</span>
      <span class="ppamSkillListing">PyQT</span>
      <span class="ppamSkillListing">GLSL</span>
      <span class="ppamSkillListing">JavaScript</span>
    </div>

    <div class="procPagesAboutMe-subHeaderStyle">
      <span>New York Metropolitan Area</span>
      <span><a href="mailto:trancor@metal-asylum.net" alt="Email me!">email</a></span>
    </div>
    
    <br><div class="ppamHBar"></div>

    <br>
    <br><div class="procPagesAboutMe-infoStyle">
      I'm given the title '<span class="textNudge">Technical Artist</span>' (<span class="textItalic">when doing real-time jobs</span>)
      <br>&nbsp;&nbsp; or '<span class="textNudge">Technical Director</span>' (<span class="textItalic">on films</span>)
      <br>&nbsp;&nbsp;&nbsp;&nbsp; or '<span class="textNudge">Creative Technologist</span>' (<span class="textItalic">for immersive</span>)
      <br>It's all the same types of mental challenges though,
      <br>&nbsp;&nbsp; Just in different mediums of digital graphics.
    </div>
    

    <br>
    <div class="textItalicBox">So I says, blue M&amp;M, red M&amp;M, they all wind up the same color in the end.</div>
    <div class="textDrinkMeAlice innerTextEnd"> - <span class="textNudge">Homer Simpson</span></div>
    
    <br>
    <div class="procPagesAboutMe-infoStyle">
      Ya know... I don't really know what I am,
      <br>&nbsp;&nbsp; I just know I like figuring out puzzles, and for the life of me, can't seem to stop my fidgety fingers.
      
      <br><br>Always gotta be tapping away at some code, 
      <br>&nbsp;&nbsp; or building some diy contraption, 
      <br>&nbsp;&nbsp; or 3d modeling, 
      <br>&nbsp;&nbsp; or sewing, 
      <br>&nbsp;&nbsp; or writing, 
      <br>&nbsp;&nbsp; or ... well, you get the idea.

      <br><br>An undiagnosed something-or-another,
      <br>&nbsp;&nbsp; Who spawned-in with the energy befitting a gift from the mythical Red Bull itself!
      <br>
      <br>
    </div>
  </div></div><div class="procPageSectionContentStyle pagesVisOn procPagesSectionActive" id="3"><div class="procPagesInnerContentStyle procPagesSectionActive pagesVisOn">
      <div class="procPagesSpacer"></div>
    <div class="procPagesAboutMe-infoStyle">
      I started my dive into AI in 2008 writing a Boid / Crowd system for my thesis while in art college, School of Visual Arts.
      <br>&nbsp;&nbsp; It was an insane particle script + 3d animation cycles in Maya haha.
      <br>Then I did Boid movement, navigation, &amp; obstacle detection in animated films for 5 years at Blue Sky Studios, using Houdini.
      <br>
      <br>I dove into Style-Transfer AI &amp; Long Short-Term Memory (LSTM) training in 2019-2020,
      <br>&nbsp;&nbsp; Like making a Node.js server (web site) understand my voice &amp; auto google search for me.
      <br>
      <br>Since then, I've been developing different multi-media AI structures in my spare time.
      <br>
      <br><div class="procPagesAboutMeBar"></div>

      <br>In 2015 I decided I'd cram a machine learning AI into a single-board computer, a Jetson TK1, by the end of 2026.
      <br>&nbsp;&nbsp; Something that could write down what I say,
      <br>&nbsp;&nbsp; Use vision to understand an object simply went out of frame.
      <br>&nbsp;&nbsp;&nbsp;&nbsp; Yet "knows" if it looks over, the object is still there;
      <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 'Long Term Attention'
      <br>
      <br>At the end of 2023, this evolved into a deep learning AI crammed into, likely, a Jetson Nano.
      <br>&nbsp;&nbsp; As something to infer what I mean, from what I say,
      <br>&nbsp;&nbsp; Or give a "thought" on what it saw or heard in the world around it.
      <br>

      <br><span class="innerCenter">
        'Machine Learning' is AI that can learn basic patterns.
        <br>'Deep Learning' is Machine Learning,
        <br>But uses neural networks to form patterns of patterns.
      </span>

      <br>
      <br>Realistically, I'd just be happy to make something that can understand what I say and can give a <span class="textItalic">semi</span> coherent response without an internet connection.
      <br>
      <br>I'm yet to begin on the core of the AI, as I'm still testing different structure's ability in adapting to stimuli.
      <br>

      <br><span class="innerCenter">
        You could guess,
        <br>All the recent AI stuff has been quite serendipitous for my creation!
      </span>

      <br><div class="procPagesAboutMeBar"></div>
      
      <br>For my 2026 goal, I've been exploring <span class="textNudge">Graph Attention Network</span> (<span class="textNudge">GAT</span>) artificial intelligence.
      &nbsp;As GATs allow me to treat 'concepts' as 'objects', rather than sections of words/pixels as a tensor or 'piece of a concept'.
      <br>
      <br><span class="innerCenter">
        GATs are a type of neural network that considers the relationships between data points.
        <br>As a type of Graph Neural Network (GNN),
        <br>Its best for predicting connections between ideas / things / data in a system.
      </span>
      
      <br><div class="procPagesAboutMe-infoStyle">
        GNNs are commonly used for "<span class="textNudge">Recommendation Systems</span>",
        <br>&nbsp;&nbsp;&nbsp;&nbsp; <span class="textItalicBox">Hey, you might know <span class="textNudge">Jim Bob McGee</span>!!</span>
        <br>&nbsp;&nbsp; But GATs could be used for so much more!
      </div>

      <br>I've been working on a general-purpose neuron that adjusts its own connections during prediction;
      <br>&nbsp;&nbsp; So the same system could learn my voice on the fly, as well as sensor signals connected to the Jetson computer.
      <br>
      <br>Since its the Structure in a GAT that causes regions of neural activation based on stimuli,
      <br>&nbsp;&nbsp; It forms a result <span class="textDrinkMeAlice">(prediction)</span> after subsequent activations, as-though compounding ripples in a pond.

      <br>
      <br><span class="innerCenter">Rather than a field of numbers aligning to yield a prediction,
      <br>&nbsp;&nbsp; It's the structure of neural connections which manipulates the data.
      </span>
      
      <br>I've been going in a direction that should yield a similar result to a Recurrent Neural Network (RNN), but with a different mental structure.
      <br>&nbsp;&nbsp; With that general-purpose neuron, I can provide text, images, audio histograms, etc. to the network.
      <br>
      <br><span class="innerCenter">RNNs can be used for/in nearly any ai,
        <br>Best for detecting patterns in sequential data,
        <br>Like time-based events or words in text.
        <div class="procPagesAboutMeSpacer"></div>
        They are the basis for many types of ai, like LSTMs;
        <br>And can be used as part of LLMs, like ChatGPT.
      </span>


      <br> The GAT will create connections from initial random data points, sample the differences, then pass the 'prediction' forward and 'back' in the chain, and adjust the connections based on their revisit to the same data in the current 'prediction'.
      <br>&nbsp;&nbsp; Relying on localized regions of sub-networks to recurrently process the data
      <br>
      <br>It should be self-taught discrimination of attention between neurons;
      <br>&nbsp;&nbsp; Like in the human brain.
      <br><div class="textSkew">&nbsp;&nbsp;&nbsp;&nbsp; (When the purple circles go red in the GAT video, first vid)</div>
      
      <br>
      <br><div class="procPagesAboutMeBar"></div>
      
      <br><span class="textNudge">How about an <span class="textNudge">Echo State Network</span> (<span class="textNudge">ESN</span>) AI I wrote in the spring-summer of 2024?</span>
      <br>
      <br><span class="innerCenter">An ESN is a type of RNN,
        <br>Which considers time in its prediction.
        <br>It thinks about past events to predict future events.
        <div class="procPagesAboutMeSpacer"></div>
      </span>
      
      <br>Since an ESN brain can learn on the fly, why not feed it some videos I made?
      
      <br>
        <div class="procPagesAboutMeSpacer"></div>
        Currently I'm not using my ESN's predicted movement for anything in python,
        <br>&nbsp;&nbsp; The next step would be introducing a base image to motion-transfer / reference.
        <br>However did build a simple version in Unity to learn player combos + movement over time.
        <div class="procPagesAboutMeSpacer"></div>
        <span class="innerCenter">So I'm mostly just learnin' while watching my ai learnin'!</span>
        <div class="procPagesAboutMeSpacer"></div>
        
        <br>In the videos, I had the "reservoir" set to 15 times steps, you'll notice about every 15 frames the brain shifts.
        <br>By frame ~45, it's learned some patterns in the X video.
        <br>The brain seems to completely melt at ~75 &amp; rebuild itself by ~95. 
        
        <br><br>It should be happenstance that the brain shifts when the reservoir fills;
        <br>The brain should shift, but the 15-frame fill might be a bug in my logic,
        <br>&nbsp;&nbsp; Or maybe its just a coincidence ::shrugs::
        <br>But it's detecting patterns in motion!
      
      
      <br><br><div class="procPagesAboutMeBar"></div>
      
      <br>
      <br>If you couldn't tell, I'm training my AIs on my own works.
      <br>A personally made AI trained on personally made images / videos / photos / code / writing.
      <br>&nbsp;&nbsp; That means I can copyright my generations, right?
      <br>&nbsp;&nbsp;&nbsp;&nbsp; If I made every aspect of the AI &amp; training data?
      <br>
      <br>
      <div class="textFullRight">- February 2025</div>
      <br>
      <br>
      <br>I've begun on the core of the AI, as of May 24th, 2025.
      <br>&nbsp;&nbsp; I have the beginnings of a 'Micro-Term' memory implemented to act as a gated-attention during inference.
      <br>This, paired with automatic graph edge splitting ('Dynamic' in DGNN or DGAT) and use of geometric clustering, seems to be giving me values of a "remembered" object when it's outside of the dataset.
      <br>&nbsp;&nbsp; Bodily awarness of limbs, objects outside of the field of view, and other 'long term' tensors/classifications at a temporary scale.
      <br>
      <br>It's a 4d kernel, in that it uses an ESN to train on it's own mistakes,
      <br>&nbsp;&nbsp; Basing it's decisions on prior back-propagation states/adjustments.
      <br>&nbsp;&nbsp; The beginnings of a meta-learning process, hehe.
      <br>
      <br>I'm using a method I'm calling 'Stack Crunching',
      <br>&nbsp;&nbsp; Where I agregate the time dependent weights into a "checkpoint" of sorts.
      <br>&nbsp;&nbsp; This allows the ESN to have a 'baseline' understanding of data that I can parse into with vectors calculated from tensor weights found within a quantized version of the input data.
      <br>
      <br>You can assume that the 'ESN' is not a standard 'Echo State Network' anymore.
      <div class="textFullRight">- May 2025</div>
    </div>
  </div></div></div></div><div class="procPagesInnerAfterBase procPagesInnerAfter"></div></div></div>
            </div>
            
            <!-- -- -- -- -->

            <div class="footerBarParent">
                <div id="footerBar" pages-default-class="defaultPage_footerBar" class="footerBar aboutMePage_footerBar">
                    <div class="leftFooter versionStyle">
                        <a href="https://github.com/ProcStack/pxlNav" target="_blank">[: pxlNav <span class="pxlNavVersion" versionadded="v0.0.28-dev">v0.0.28-dev</span> :]</a>
                    </div>
                    <div>
                    </div>
                    <div class="rightFooter">
                      <a href="https://github.com/ProcStack" target="_blank">ProcStack</a> / <a href="https://www.youtube.com/@trancorwd" target="_blank">Trancor</a> / <a href="mailto:trancor@metal-asylum.net" target="_blank">Kevin Edzenga</a><span class="squashInLowRes">; 2025</span>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <canvas id="pxlNav-coreCanvas" height="600" width="800" class="pxlNav-coreCanvasStyle" data-engine="three.js r171" style="width: 800px; height: 600px;"></canvas>

    <script type="module" id="pxlNavModule" src="../js/ProckStackGitio.js?v=2025-02-08"></script>




<div class="guiWindowBackground fader visOff" style="display: none;"></div></body></html>