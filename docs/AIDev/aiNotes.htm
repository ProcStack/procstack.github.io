<!--
// ProcStack.Github.io - 2024,2025
// By Kevin Edzenga
// Kevin@Metal-Asylum.Net
//
// --
// 
// Thanks for viewing the source code for procstack.github.io!
//   If you have any questions, feel free to reach out to me at the email above.
//
// If you'd rather see the source code on the repo -
//   https://github.com/ProcStack/procstack.github.io/tree/main/docs
//     For page content, see `./pages`
--><!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"> 
  <link rel="sitemap" href="https://procstack.github.io/sitemap.xml" type="application/xml">
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=5.0">
  <meta name="theme-color" content="#000822">
  <meta name="robots" content="index, follow, ai:json">
  <meta name="revisit-after" content="14 days">
  <meta name="fragment" content="!">
  <!-- Note : connical, description, & keywords update with page changes -->
  <link rel="canonical" href="http://localhost:3000/AIDev/aiNotes.htm" id="canonicalLink">
  <meta name="description" content="AI development &amp; research by ProcStack, including work on Graph Attention Networks (GAT), Echo State Networks (ESN), and other AI structures.">
  <meta name="keywords" content="AI, Artificial Intelligence, Machine Learning, Deep Learning, Graph Attention Network, GAT, Echo State Network, ESN, Neural Networks, AI Development, ProcStack, Kevin Edzenga">
  <meta name="author" content="Kevin Edzenga">

  <!-- AI/LLM Data Discovery -->
  <meta name="robots" content="index, follow">
  <meta name="ai:data-source" content="https://procstack.github.io/bots/siteContent.json">
  <meta name="ai:data-manifest" content="https://procstack.github.io/data-manifest.json">
  <meta name="ai:content-api" content="https://procstack.github.io/bots/">
  <link rel="alternate" type="application/json" href="https://procstack.github.io/bots/AIDev_aiNotes.htm.json" title="Site Content Data">
  <link rel="data-manifest" type="application/json" href="https://procstack.github.io/data-manifest.json" title="Data Sources Manifest">
  <link rel="ai-meta-spec" href="https://procstack.github.io/bots/ai-metadata-spec.html">

  <!-- The Socials -->
  <meta name="googlebot" content="index, follow, ai:json">
  <meta name="google" content="nositelinkssearchbox">
  <meta name="google" content="notranslate">
  <meta name="google" content="nositelinkssearchbox">

  <meta name="og:title" content="Notes &amp; Research - AI Development - ProcStack">
  <meta name="og:description" content="AI development &amp; research by ProcStack, including work on Graph Attention Networks (GAT), Echo State Networks (ESN), and other AI structures.">
  <meta name="og:image" content="https://procstack.github.io/images/ProcStack_th.jpg">
  <meta name="og:url" content="http://localhost:3000/AIDev/aiNotes.htm">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Notes &amp; Research - AI Development - ProcStack">
  <meta name="twitter:description" content="AI development &amp; research by ProcStack, including work on Graph Attention Networks (GAT), Echo State Networks (ESN), and other AI structures.">
  <meta name="twitter:image" content="https://procstack.github.io/images/ProcStack_th.jpg">
  <meta name="twitter:url" content="https://procstack.github.io">
  <meta name="twitter:domain" content="procstack.github.io">
  <meta name="twitter:label1" content="Written by">
  <meta name="twitter:data1" content="Kevin Edzenga">

  <title>Notes &amp; Research - AI Development - ProcStack</title>
  <meta name="title" content="Notes &amp; Research - AI Development - ProcStack">
  
  <script type="application/ld+json" id="ldjsonSchema">{
  "@context": "https://schema.org",
  "@type": "WebPage",
  "name": "AI Development Notes",
  "description": "AI development & research by ProcStack, including work on Graph Attention Networks (GAT), Echo State Networks (ESN), and other AI structures.",
  "keywords": "AI, Artificial Intelligence, Machine Learning, Deep Learning, Graph Attention Network, GAT, Echo State Network, ESN, Neural Networks, AI Development",
  "url": "https://procstack.github.io/AIDev/aiNotes.htm",
  "image": "https://procstack.github.io/images/ProcStack_th.jpg",
  "author": {
    "@type": "Person",
    "name": "Kevin Edzenga",
    "alternateName": [
      "ProcStack",
      "Trancor"
    ],
    "url": "https://procstack.github.io"
  }
}</script>
  <meta name="google-site-verification" content="BiFfMHYTXO2SVuwHbCsth_IVUmyLgIpPUfEfnDPgP00">
<link type="text/css" id="procPagesStylesheet" rel="stylesheet" href="../style/ProcStackStyle.css"><link type="text/css" id="pxlNavStylesheet" rel="stylesheet" href="../style/pxlNavStyle.min.css"></head>

<!-- -- -- -- -->




<!-- Bypassing Youtube Player API for now -->
<!--   Causing pxlNav pre-processing errors -->
<!--     To be fixed through pxlNav in the future, but for now... -->
<!-- <script src="https://www.youtube.com/iframe_api" async></script> -->

<!-- -- -- -- -->

<body>
  
<!-- -- -- -- -- -- -->
<!-- SEO for Robots -- -->
<!-- -- -- -- -- -- -- -- -->
<nav aria-hidden="true" style="display:none;" role="navigation" aria-label="Site structure for crawlers">
  <a href="/Init.htm" rel="bookmark">Initialize - Welcome and Introduction</a>
  <a href="/pxlNav/Explore.htm" rel="bookmark">pxlNav Framework - 3D Navigation Technology</a>
  <a href="/MakingOf/Development.htm" rel="bookmark">Making Of - Development Process</a>
  <a href="/ProjectsLinks/procstack.github.io.htm" rel="bookmark">Projects and Repositories Portfolio</a>
  <a href="/Blog/Technical.htm" rel="bookmark">Technical Blog and Tutorials</a>
  <a href="/AboutMe/What_am_I.htm" rel="bookmark">About Kevin Edzenga - Technical Artist</a>
</nav>

  <!-- -- -- -- -->

	<div id="verbErrorConsole">
	</div>
  
<!-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -->
<!-- Primary site & `pxlPages` Implementation  -- -->
<!-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -->
    <div id="procPagesMainBlock" class="procPagesMainBlockStyle pagesFader pagesVisOn">
        <div id="procStackGitParent" class="procStackGitParentStyle">
            <div id="procPagesNavBlock" pages-default-class="procPagesNav_defaultStyle" class="procPagesNavBlockStyle procPagesNav_aiDevStyle">
                <div id="procPagesNavHeader" class="procPagesNavHeaderStyle gpnhScreenMedia">
                  <span class="squashInLowRes">_ProcStack_</span>
                </div>
                <nav id="procPagesNav" class="procPagesNavStyle" role="navigation" aria-label="Main navigation">
                  <a href="Init.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="init" page-name="Init" aria-label="Navigate to initialization and welcome page" role="button">Init.</a>
                  <a href="pxlNav.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="pxlNav" page-name="pxlNav" aria-label="Learn about pxlNav, this site's 3D navigation framework" role="button">pxlNav</a>
                  <a href="MakingOf.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="makingOf" page-name="MakingOf" aria-label="Behind the scenes of building this site" role="button" style="display: none;">Making<span class="procPagesHideWhenThin"> Of</span>...</a>
                  <a href="ProjectsLinks.htm" class="pageLinkStyle" pxlroomname="SaltFlatsEnvironment" pxlcameraview="defaultCam" page-name="ProjectsLinks" aria-label="View my repositories and project portfolio" role="button">Projects</a>
                  <a href="Blog.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="defaultCam" page-name="Blog" aria-label="Read my technical blog posts and tutorials" role="button" style="display: none;">Blog</a>
                  <a href="AIDev.htm" class="pageLinkStyle procPagesNav_aiDevActiveStyle" pxlroomname="CampfireEnvironment" pxlcameraview="aiDev" page-name="AIDev" aria-label="Read my technical blog posts and tutorials" role="button">AI Dev</a>
                  <a href="AboutMe.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="aboutMe" page-name="AboutMe" aria-label="Learn about me and my background" role="button"><span class="procPagesHideWhenThin">About&nbsp;</span>Me</a>
                  <span id="procPagesToggleDOM" class="procPagesToggleDOMStyle" role="group" aria-label="View mode controls">
                    <a class="pageLinkStyle pageLinkEventStyle" pageevent="ToggleDOM" pagevalue="1" role="button" tabindex="0" aria-label="Switch to full 3D environment view" title="Switch to 3D view">§</a>
                    <a class="pageLinkStyle pageLinkEventStyle" pageevent="ToggleDOM" pagevalue="0" role="button" tabindex="0" aria-label="Switch back to page content view" title="Switch to page content view" style="display: none;">¤</a>
                  </span>
                </nav>
            </div>

            <!-- -- -- -- -->
            
            <div id="pxlPagesContentBlock" class="pxlPagesContentBlockStyle gpcpVisibleStyle heightFader">
              <div id="pxlPagesContentParent" class="pxlPagesContentParentStyle"><div class="gpcpVisibleStyle procPagesContentStyle procPagesPlacementTripleStyle aiDevPageStyle pagesFader pagesVisOn"><div class="procPagesInnerBeforeBase procPagesInnerBefore"></div><div class="procPagesInnerStyle procPagesParentStyle procPagesLayoutTripleStyle aiDevPageParentStyle procPageNoMediaStyle" id="pxlPage_AIDev"><div class="procPageHeader procPagesHeaderStyle">AI Development</div><div class="procPagesHeaderLine aiDevPage-headerLine"></div><nav role="navigation" aria-label="Page sections" class="procPageSectionList aiDevPage-sectionNavListStyle"><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to My Introduction section">My Introduction</div><div style="height: 3px;"></div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to ESRGAN Upresser section">ESRGAN Upresser</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to ESN Motion Prediction section">ESN Motion Prediction</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to GNN Exploration section">GNN Exploration</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to GAT &amp; Language section">GAT &amp; Language</div><div style="height: 10px;"></div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle procPagesNavActive aiDevPage-sectionNavButtonActiveStyle" role="button" tabindex="0" aria-label="Navigate to Notes &amp; Research section">Notes &amp; Research</div></nav><section class="procPageMediaView aiDevPageScrollbarStyle" role="region" aria-label="Media gallery for AIDev page sections" aria-describedby="Dynamic media content that changes based on selected section" style="align-items: center; display: none;"><div class="procPagesMediaListStyle pagesVisOff"><iframe src="https://www.youtube-nocookie.com/embed/XJu-UJrI6yk" title="Useful AI for Visual Graphics" frameborder="0" allow="encrypted-media; picture-in-picture" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="true" class="procPagesMediaStyle procPagesLimitWidthStyle"></iframe></div></section><section class="procPageContentView aiDevPageScrollbarStyle" role="main" aria-label="Primary content area for AIDev page" aria-describedby="Main content that updates dynamically based on selected section navigation"><div class="procPageSectionContentStyle pagesVisOff" id="0"><div class="procPagesInnerContentStyle pagesVisOff">
    <div class="textSpacer"></div>
    <div class="procPagesAboutMe-infoStyle">
      <br>I started my dive into AI in 2008 writing a Boid / Crowd system for my thesis while in art college, School of Visual Arts.
      <br>&nbsp;&nbsp; It was an insane particle script + 3d animation cycles in Maya haha.
      <br>Then I did Boid movement, navigation, &amp; obstacle detection in animated films for 5 years at Blue Sky Studios, using Houdini.
      <br>
      <br>I dove into Style-Transfer AI &amp; Long Short-Term Memory (LSTM) training in 2019-2020,
      <br>&nbsp;&nbsp; Like making a Node.js server (web site) understand my voice &amp; auto google search for me.
      <br>
      <br>Since then, I've been developing different multi-media AI structures in my spare time.
      <br>
      <br><div class="procPagesAIDevBar"></div>

      <br>In 2015 I decided I'd cram a machine learning AI into a single-board computer, a Jetson TK1, by the end of 2026.
      <br>&nbsp;&nbsp; Something that could write down what I say,
      <br>&nbsp;&nbsp; Use vision to understand an object simply went out of frame.
      <br>&nbsp;&nbsp;&nbsp;&nbsp; Yet "knows" if it looks over, the object is still there; 'Attention'
      <br>
      <br>At the end of 2023, this evolved into a deep learning AI crammed into, likely, a Jetson Nano.
      <br>&nbsp;&nbsp; As something to infer what I mean, from what I say,
      <br>&nbsp;&nbsp; Or give a "thought" on what it saw or heard in the world around it.
      <br>

      <br><span class="innerCenter">
        'Machine Learning' is AI that can learn basic patterns.
        <br>'Deep Learning' is Machine Learning,
        <br>But uses neural networks to form patterns of patterns.
      </span>

      <br>
      <br>Realistically, I'd just be happy to make something that can understand what I say and can give a <span class="textItalic">semi</span> coherent response without an internet connection.
      <br>
      <br>As of May 24th 2025, I've started on the core of the AI,
      <br>&nbsp;&nbsp; But still testing different structure's ability in adapting to stimuli.
      <br>&nbsp;&nbsp; ... It really seems like any network could work for most things, but some are better than others per task.
      <br>

      <br><span class="innerCenter">
        You could guess,
        <br>All the recent AI hullabaloo (2019-...)
        <br>Has been quite serendipitous for my creation!
      </span>
    </div>
  </div></div><div class="procPageSectionContentStyle aiDevPage-blogStyle pagesVisOn procPagesSectionActive" id="7"><div class="blogManagerBlockStyle aiDevPage-blogStyle"><div class="blogEntryListStyle procPagesSectionActive pagesVisOn"><button class="blogEntryListingStyle">
        Being &amp; Becoming
        <div class="blogSubListingStyle">:: 2025-10-05</div></button><button class="blogEntryListingStyle">
        Bodily Autonomy
        <div class="blogSubListingStyle">:: 2025-10-02</div></button><button class="blogEntryListingStyle">
        Dreamy Meanderings
        <div class="blogSubListingStyle">:: 2025-08-30</div></button><button class="blogEntryListingStyle">
        Hoping for Nuance
        <div class="blogSubListingStyle">:: 2025-08-16</div></button><button class="blogEntryListingStyle">
        Neural Bundles
        <div class="blogSubListingStyle">:: 2025-08-02</div></button><button class="blogEntryListingStyle">
        Feedback Systems
        <div class="blogSubListingStyle">:: 2025-08-01</div></button><button class="blogEntryListingStyle">
        Tensor Terrain Adaptation
        <div class="blogSubListingStyle">:: 2025-07</div></button><button class="blogEntryListingStyle">
        Stack Crunching
        <div class="blogSubListingStyle">:: 2025-05</div></button><button class="blogEntryListingStyle">
        My Training Data
        <div class="blogSubListingStyle">:: 2025-02</div></button></div><div class="blogEntryListMobileStyle"><button class="blogEntryListingStyle blogMobilePrev">◀ Older</button><button class="blogEntryListingStyle blogMobileCurrent">
      Being &amp; Becoming
      <div class="blogSubListingStyle">:: 2025-10-05</div></button><button class="blogEntryListingStyle blogMobileNext blogDisabledButtonStyle">Newer ▶</button></div><div class="blogEntryContentStyle aiDevPage-blogContentStyle procPagesSectionActive pagesVisOn"><div class="procPagesTempContentStyle">
    <div class="textSpacer"></div>
    <div class="procPagesAboutMe-infoStyle blogTempContentStyle">
      These are my random thoughts or research on AI.

      <br>
      <span class="showOnMobile"><br>Tap the Entry Title above to open the Blog Entry List.</span>

      <br>And no, I'm not using ai to speak for me here.
      <br>These are my thoughts, how ever scattered they may be.
    </div>

      <br><br><br><div class="procPagesAIDevBar"></div>
  </div><div class="aiDevPage-blogContentStyle" style="display: block;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Being &amp; Becoming</h1><p class="blogEntryDateStyle">2025-10-05</p><p class="blogEntryReadTimeStyle">3<span class="textShrinkRay">&nbsp;</span>-<span class="textShrinkRay">&nbsp;</span>5 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  On the topic of nothingness and somethingness, Hegel started with what it means to Exist at all, before Being and Nothingness can have meaning.
  <br>&nbsp;&nbsp; That once something has a purpose beyond the innate attribute of existing, "Actuality" or running the class constructor, then the bounds of Being and Nothing can be defined.
  <br>&nbsp;&nbsp; I need to read more Hegel, he's one of the bigger names I haven't read as much of.

  <br><br> Something about that got me thinking about the big bang. 
  <br>&nbsp;&nbsp; Something from nothing has been the running theory of the Universe with the Big Bang for some time now.
  <br>&nbsp;&nbsp; That there could be a source of creation beyond the wall between us and the void, simply by nature of how we exist within physics, rather than above physics.

  <br><br> If you zoom super far in, at planck length scales, there is a Quantum Foam, like frothing, that exists from these nano-blackholes popping in'n'out of existence.
  <br>&nbsp;&nbsp; There's plenty of speculation as to where it's source comes from, but it's mostly agreed its gravitational forces causing it.
  <br>&nbsp;&nbsp; ( <a href="https://en.wikipedia.org/wiki/Quantum_foam" target="_blank">wikipedia.org/wiki/Quantum_foam</a> )
  
  <br><br>I'm dubious of this, siding with some theories from String Theory &amp; M-Theory, vibrations from higher dimensions causing that bubbling to occur.  But String &amp; M-Theory are still being worked out by people smarter than me.
  <br>&nbsp;&nbsp; I mostly think this cause of how electrons exist in duality as a particle and wave. As if they were a function of frequencies moving through space-time.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; That the representation of an electron might merely be a compounding wave interacting in space.
  
  <br><br> Keep in mind, I aint some fizzy-cyst, this is just an interest of mine.
  <br>&nbsp;&nbsp; So I might have some things wrong.
  <br>&nbsp;&nbsp; But if you're interested, look into the Kaluza-Klein theory, and how it tried to unify gravity and electromagnetism through higher dimensions.  This lead into String Theory and M-Theory.
  <br>&nbsp;&nbsp; ( <a href="https://en.wikipedia.org/wiki/Kaluza%E2%80%93Klein_theory" target="_blank">wikipedia.org/wiki/Kaluza-Klein_theory</a> )

  <br><br><div class="procPagesAIDevBar"></div>

  <br>This foam acts as a perturbation to space around it.
  <br>&nbsp;&nbsp; It's the "energy" in the void.
  <br>&nbsp;&nbsp; The Something in Nothingness.

  <br><br> In my mind, it makes sense that these slight undulations in space could cause entropy to begin, if there was actual homeostasis in the early Universe.
  <br>&nbsp;&nbsp; But there wasn't homeostasis, due to the different distributions of antimatter vs matter in the early Universe.
  <br>&nbsp;&nbsp; So I wonder if the foam could have added to the early incendiary forces which lead to quarks forming into protons &amp; neutrons, as electrons cooled down and the mass started to aggregate into atoms in early times.

  <br><br><div class="procPagesAIDevBar"></div>

  <br><br> I'm moithering a bit.

  <br><br> To Exist and Become in AI requires similar perturbations, noise patterns to shift AIs current understanding, stochastically shifting its 'ideas' for better perspectives on the data.

  <br><br> I've been calling these 'Lighthouses' for a while now.  They are the landmarks for a sense of reality for the AI itself.
  <br>&nbsp;&nbsp; While I still feel like they shouldn't be required, most ai uses some form of stocastic noise pattern to help shift understanding of concepts while training or inference.
  <br>&nbsp;&nbsp; It's Learning AI that will use random/noise.
  <br>&nbsp;&nbsp; There are deterministic ais, such as the chess playing Stockfish which doesn't use noise. But for AIs outside of planning and strategy, random is used.

  <br><br> Should that noise pattern be altered while it's being used as the Lighthouse, the current step of math and logic in that AI becomes corrupted.
  <br>&nbsp;&nbsp; At least as far as I've seen.

  <br><br> AI's "being" is bound to its skewed perceptions.
  <br>&nbsp;&nbsp; ... We all kinda are ...
  <br>&nbsp;&nbsp; But should an AI not have that noise-skew, the AI doesn't usually "become" anything of any usable behaviors.

  <br><br> ( Certain noise isn't that pivotal to "existence", but noise aids in the final AI becoming itself. )

  <br><br> I still don't like the idea of Lighthouses for AI.
  <br>&nbsp;&nbsp; But would I be stripping away the AI's personality for raw deterministic responses,
  <br>&nbsp;&nbsp;&nbsp;&nbsp; If I find a way around Lighthouses?

  <br><br><div class="textFullRight">- October 5th 2025</div>
</p><p class="blogEntryTagStyle">research, nothing, something, lighthouses, existence</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Bodily Autonomy</h1><p class="blogEntryDateStyle">2025-10-02</p><p class="blogEntryReadTimeStyle">2<span class="textShrinkRay">&nbsp;</span>-<span class="textShrinkRay">&nbsp;</span>3 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  I coined a term for myself while working out the logic for "Human First" needs.

  <br><br> Autononautonomy

  <br><br> Yes, I was drunk and laughed at the idea of needing to teach the AI how to learn its not autonomous with regards to its own body.
  <br>&nbsp;&nbsp; That it has a brain separated from its body, in a way that it can't die, merely be turned off until turned back on. That its body can be rebuilt and upgraded at will, requiring power cycling.
  <br>&nbsp;&nbsp; That the bot's goals are lesser than that of humans, in meat-space.
  <br>&nbsp;&nbsp; Like by turning them off, The Big Red Button.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; ( <a href="https://www.youtube.com/watch?v=3TYT1QfdfsM" target="_blank">youtube - Computerphile - AI "Stop Button" Problem</a> )

  <br><br> Dare I say an allegory for the human soul if you believe in life after death or re-incarnation.
  <br>&nbsp;&nbsp; They're not dead, only their body is dead.
  <br>&nbsp;&nbsp; But to then teach pain through software limitations, anti-rewards, in order to start on a form of Empathy in the ai.

  <br><br> So a distinction is made between humans and AI, yet pain and emotion needs to be stimuli to the bot for Empathy to work.
  <br>&nbsp;&nbsp; Understanding Pain and Pleasure to some degree where it can better understand Human Safety.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; I'm still working this out...

  <br><br> Everything I'm talking about is theory at the moment.  But it doesn't seem like every company is attempting to implement Asimov's 3 Rules of Robotics...
  <br>&nbsp;&nbsp; There are Alignment teams, but it seems like it's to protect themselves from potential lawsuits, more than actual human safety.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; But some companies are better than other's at least.

  <br><br> So why is it, of 16 LLMs tested, they would choose to end the life of a worker attempting to turn them off?
  <br>&nbsp;&nbsp; ( <a href="https://www.anthropic.com/research/agentic-misalignment" target="_blank">anthropic.com/research/agentic-misalignment</a> )

  <br><br> I was going to link a video of these boxing robots aggresively approaching people, but it seems like they are all "pranks" that someone might be controlling them off camera.
  <br>&nbsp;&nbsp; I don't know enough about these boxing bots to say anything more, and don't want to give an ignorant opinion on them.

  <br><br> But we've had Asimov's writings for decades now ...
  <br>&nbsp;&nbsp; And Gibson... And Stephenson...

  <br><br> Please implement human safety ...

  <br><br><div class="textFullRight">- October 2nd 2025</div>
</p><p class="blogEntryTagStyle">research, autonomy, safety, human first, asimov</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Dreamy Meanderings</h1><p class="blogEntryDateStyle">2025-08-30</p><p class="blogEntryReadTimeStyle">3<span class="textShrinkRay">&nbsp;</span>-<span class="textShrinkRay">&nbsp;</span>5 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  I've been looking into dream research again.
  <br>&nbsp;&nbsp; For a while I've been planning on a meditative dream state for tensor field testing.
  <br>&nbsp;&nbsp; Testing different stimuli on the current networks state to produce outputs to test and compare with known 'Real' data like in a GAN network.
  
  <br><br> What interests me about dreams this time, is the dream-building process of dreams; which seems somewhat agreed upon by scientists.
  <br>&nbsp;&nbsp; Like the foundation of a dream, which gathers ideas like fly-paper catching bugs.
  <br>&nbsp;&nbsp; ( <a href="https://en.wikipedia.org/wiki/Activation-synthesis_hypothesis">Activation-Synthesis Theory</a> &amp;&amp; <a href="https://en.wikipedia.org/wiki/Antti_Revonsuo" target="_blank">Threat Simulation Theory</a> )

  
  <br><br> I've always been fascinated by dreams since I was young.
  <br>&nbsp;&nbsp; Like a little movie story generator in my brain; with super natural abilities or random scale changes
  <br>&nbsp;&nbsp; (Honey I Shrunk The Kids was quite popular back when)
  
  <br><br> Until I was maybe 20, I just assumed movie dream sequences were a stylistic choice to not bore people with their black'n'white or grayscale imagery.
  <br>&nbsp;&nbsp; That was until I asked someone if their dreams looked like the movie's dream sequences.  They told me that, yeah, but their dream colors are more vivid than the movie.
  
  <br><br> Wait.... Color in dreams??
  
  <br><br> The further I asked individuals, the more I found out that dreaming of flying through nebulas while fixing a broken panel on a space ship wasn't too common.
  <br>&nbsp;&nbsp; Or running up some Kaiju monsters arm to round house kick em in the face, would really only be after they watched Attack On Titan.
  
  <br><br> ...The shadow people though... I could do without the shadow people. Freaky ass, ferrofluid moving, 'blank' people...
  
  <br><br> Of course I started looking into what research existed for people dreaming in black and white or grayscale.
  <br>&nbsp;&nbsp; They say some 7-11% dream in gray, but that it's in older people; so they attributed it to people growing up with black'n'white tv. (Schredl, 2008)

  <br><br> I'm not even 40 yet. If my childhood would have impacted my dream colors, they'd be black'n'green like some DOS computers.
  <br>&nbsp;&nbsp; Or VGA graphics card's 256 color choices on screen, looking like Commander Keen or Duke Nukem 1/2.
  
  <br>
  <br><br> Clearly there are structural differences in the brain causing these changes in types of dreaming.
  
  <br><br> I feel I should say, as it's likely important for my personal qualia.
  <br>&nbsp;&nbsp; I don't really visualize stuff in full color in my brain. I can think of a red apple, but it's 10% colored in, but accompanied with the 'feeling' of very specific shades of reds ( and yellows, if thinking of a Jazz apple )
  <br>&nbsp;&nbsp; Mentally 'felt' colors I could easily pick out in Photoshop's color picker;
  <br>&nbsp;&nbsp;&nbsp;&nbsp; Just not fully seen in my mind's eye.
  
  <br><br> If I focus harder, maybe I can fill in the mental-image of that apple from 10% up to 25% colorized, but its just a mental-visual representation of the exact color my brain was already 'feeling'.
  
  <br><br> But my dreams don't have these color-feelings to them,
  <br>&nbsp;&nbsp; Perhaps that info is lost in my memory, and I do have color associations of objects in dreams, just they don't record to my brain's meat-memory.
  
  <br><br> I'd assume, for how many people report not having an inner-eye in their brain, there would be a lot more reports of black'n'white dreams, if they were correlated.  
  <br>&nbsp;&nbsp; I want to do more research into potential links between types of personal qualia, but that's a topic for another post.
  
  <br>
  <br><br> It seems accepted that dreams help keep areas of the brain active, sustained neural activities, while performing neural pruning.
  <br>&nbsp;&nbsp; Activating areas in the visual cortex, theme/story concepts, and fear/debate responses, as a way to keep those good connections active while the rest of the brain is doing a nightly sweep to clean up plaque and secure neural pathways.
  <br>&nbsp;&nbsp; So instead of your brain deciding it should change the connections in your visual / auditory areas of the brain, those connections stay active to reduce neural plasticity in those areas.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; ( Defensive Activation Theory - <a href="https://time.com/5925206/why-do-we-dream/" target="_blank">Time Article</a> )
  
  <br><br> ... please tell me people at least hear stuff in dreams too, haha.
  
  <br><br> But until more research is done in this field, I'll be over here dreaming up tons of people running around in dark grey environments, while I'm rebuilding some Tolkien-esk Geiger style'd gear systems,
  <br>&nbsp;&nbsp; Or riding along side tiny ant-riding warriors,
  <br>&nbsp;&nbsp; While my brain is cleaning itself and shoring up axial connections.

  <br><br><div class="textFullRight">- August 30th 2025</div>
</p><p class="blogEntryTagStyle">research, dreams, qualia</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Hoping for Nuance</h1><p class="blogEntryDateStyle">2025-08-16</p><p class="blogEntryReadTimeStyle">2<span class="textShrinkRay">&nbsp;</span>-<span class="textShrinkRay">&nbsp;</span>3 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  So, more'n more there are some rather choice words about AI online.

  <br>
  <br>I wanted to put my personal ai dev views on record somewhere, for those who care.
  
  <br>
  <br>I read the <span class="textName">I Ching</span> and it put life into a different perspective.
  <br>&nbsp;&nbsp; Letting me down the path of researching Taoism

  <br>
  <br>As with many of the other religious texts I looked into,
  <br>&nbsp;&nbsp; Amazing imagery was used to teach morals and help guide the lost,
  <br>&nbsp;&nbsp;&nbsp;&nbsp; But organized religion as a whole feels a little off to me.

  <br>
  <br>I don't hold any particular belief or religion at this point.
  <br>&nbsp;&nbsp; But I would use the cliche 'spiritual' to describe my outlook

  <br>
  <br>I then visited the Buddhist monastery in Carmel NY,
  <br>&nbsp;&nbsp; Greeted by the largest buddha statue in north america.
  <br>&nbsp;&nbsp; In awe of the multitudes of multitudes of hand-carved buddha statuettes in audience of the massive statue of buddha I pale in comparison before.

  <br>
  <br>I'd highly suggest visiting the monastery if you ever find yourself in the area!

  <br>
  <br>I think it was walking through the rows of 18 arahants statues, of those who reached nirvana, helped me realize,
  <br>&nbsp;&nbsp; Religion is about teaching the lessons of god(s),
  <br>&nbsp;&nbsp; Yet understanding balance is what's inside all of us as Humans,
  <br>&nbsp;&nbsp;&nbsp;&nbsp; Just gotta find it!

  <br>
  <br>So,
  <br>&nbsp;&nbsp; I'd like to hope I'm nuance-first with my approach to my ai development.
  <br>&nbsp;&nbsp; I'd like to believe in an AI which can understand...
  <br>&nbsp;&nbsp;&nbsp;&nbsp; That overlooked concepts matter in Health and Wellbeing.

  <br>
  <br>Realistically, the Buddhist Precepts feel like a good place to start for alignment.
  <br>&nbsp;&nbsp; Even as people.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; Which is more than I can say for myself....
  <br>&nbsp;&nbsp;&nbsp;&nbsp; I'm a hedonist at times, absurdist the rest
  <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <span class="textItalic">(Absolute terms are fun to use, hyperbole be a thing)</span>

  <br>
  <br>I very much enjoyed working on family films,
  <br>&nbsp;&nbsp; Seeing the fans in comments online,
  <br>&nbsp;&nbsp; And wish to work on more animated features soon.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; I have hope in humanity
  
  <br>
  <br>May the few not ruin it for those of us trying to explore new horizons.

  <br><br><div class="textFullRight">- August 15th,16th 2025</div>
</p><p class="blogEntryTagStyle">ethics, direction, nuance</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Neural Bundles</h1><p class="blogEntryDateStyle">2025-08-02</p><p class="blogEntryReadTimeStyle">2<span class="textShrinkRay">&nbsp;</span>-<span class="textShrinkRay">&nbsp;</span>3 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  I've been looking into neural bundles in the brain.  There is an implicit "delay" in the flow of information that I'm interested in.
  <br>&nbsp;&nbsp; As signals move between neurons, some connections take a longer path than others to get to the same destination.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; For as much as I interpreted it.

  <br>
  <br>There is 6 main layers of neurons in the cerebral cortex,
  <br>&nbsp;&nbsp; Of these, the 4th seems to allow for delays in processing.
  <br>&nbsp;&nbsp; The 5th layer then introduces a dense layer of pathways for the signals to travel through.
  <br>&nbsp;&nbsp; This is where I think another form of delay is introduced.

  <br>
  <br>I was comparing Mice and Wallaby brains,
  <br>&nbsp;&nbsp; While Mice are likely more intelligent,
  <br>&nbsp;&nbsp; Wallabies have more connections with denser pathways, it seems.

  <br>
  <br>Wallabies have more glial cells within slices of the brain compared to Mice.
  <br>&nbsp;&nbsp; But mice had more neurons in the same slices.
  
  <br>
  <br>I'd like to believe, this doesn't mean there is a "better" brain here.
  <br>&nbsp;&nbsp; But rather, different types of brains that are suited for different tasks.
  
  <br>
  <br>Wallabies are known to be social animals when food is plentiful,
  <br>&nbsp;&nbsp; Yet solitary when food is scarce.
  <br>Mice are known to be social animals,
  <br>&nbsp;&nbsp; And have shown empathy towards other mice in distress,
  <br>&nbsp;&nbsp; And share food with other mice when they are in need.
  
  <br>
  <br>Why do I bring this up?
  <br>&nbsp;&nbsp; I believe there is similar deductive reasoning, just at a different scale.
  <br>Both Wallabies and Mice are making a choice based on the environment and situation,
  <br>&nbsp;&nbsp; While considering the well-being of others, just in different ways.
  
  <br>
  <br>The delay in neural firing could be a factor in this.
  <br>&nbsp;&nbsp; So I'd like to explore this in my own AI.
  
  <br>
  <br>We all know size of the brain can determine intelligence,
  <br>&nbsp;&nbsp; But so does the structure of the brain.

  <br><br><div class="textFullRight">- August 2nd 2025</div>
</p><p class="blogEntryTagStyle">research, brain, structure</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Feedback Systems</h1><p class="blogEntryDateStyle">2025-08-01</p><p class="blogEntryReadTimeStyle">1 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;"><br>
  I'd like to believe I'm moving in the right direction with the feedback systems I'm developing.
  <br>&nbsp;&nbsp; But been further creating other architectures to see how they operate.

  <br><br>I created a GAN for upressing, which helped me understand a bit better the pairing of mental structures between both our brain's hemispheres.
  <br>&nbsp;&nbsp; So I added a time based memory to check if the training was moving in the right direction.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; It definitely helped guide training a bit quicker.

  <br><br>Shows my knowledge base that I'm impressed by back-up supported learning...
  <br>&nbsp;&nbsp; But'is proof of concept!
  
  <br><br>Adversarial networks exist in nature to guide a 'single' thought's path.
  <br>&nbsp;&nbsp; Yet in the case of Group Think between humans,
  <br>&nbsp;&nbsp;&nbsp;&nbsp; Balance is never reached.
  
  <br><br><div class="textFullRight">- August 1st 2025</div>
</p><p class="blogEntryTagStyle">research, feedback, GAN</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Tensor Terrain Adaptation</h1><p class="blogEntryDateStyle">2025-07</p><p class="blogEntryReadTimeStyle">2 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  With a bit more research into the types of minds that brought us DeepMind, and their work on GNN networks,
  <br> I read a bit of Petar Velickovic's work on topological deep learning and the geometry of GNNs.
  <br> Coming to find out that my idea of 'Stack Crunching' is similar to 'Squashing' in GNNs.
  <br>
  <br> So I've been inspired to propperly name my neural structure-
  <br>It's a <span class="textName">Dynamic Pointer-Attention Message Passing Neural Network with Affine-Projections</span>
  <br>&nbsp;&nbsp; or a <span class="textName">dPA-MPNN</span>
  
  <br><br> But I must say, this isn't Affine Projections like in the papers,
  <br>&nbsp;&nbsp; It's more like a 'projection' of the data into 'pointer' space;
  <br>&nbsp;&nbsp; Actual Affine Matricies.
  <br>&nbsp;&nbsp;&nbsp;&nbsp; I am a Technical Artist first before an AI Researcher after all, BOIDS!
  <br>
  <br>It all comes down to BOOOOIIIIIDDDDSSSSSS instead of Adam, baby!
  <br>Because, what is Adam? It's a direction to move in a field of numbers, with momentum and a learning rate.
  <br>&nbsp;&nbsp; Yet... That's just a simple Boid, now isn't it?
  <br>&nbsp;&nbsp; Just without a few of the more advanced rules, which make boids feel so alive!
  <br>
  <br>Having some Tiny Brains running around in hyperdimensional space like little buggers running around avoiding each other.
  <br>&nbsp;&nbsp; Because if they collide, double activation happens when it may not be desired.
  <br>&nbsp;&nbsp; (I'm happy I finally saw a paper on Tiny Brains, giving some of my ideas credence, cause it fits! .. in my mind.)
  <br>(Only difference is that it was a <a href="https://www.nature.com/articles/s41586-025-09142-4" target="_blank">study</a> into small biological systems, not artificial ones... but I'm gettin there!)
  
  <br>
  <br>Update : At the time, I had been seeing some papers talking about "Tiny Brains" being used in AI, hence the term.
  <br>&nbsp;&nbsp; But this biological study really helped solidify some ethereal concepts.

  <br><br><div class="textFullRight">- July 2025,<br> Updated August 2nd 2025</div>
</p><p class="blogEntryTagStyle">research, GNN, topology, MPNN, dPA-MPNN</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">Stack Crunching</h1><p class="blogEntryDateStyle">2025-05</p><p class="blogEntryReadTimeStyle">1<span class="textShrinkRay">&nbsp;</span>-<span class="textShrinkRay">&nbsp;</span>2 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  I've begun on the core of the AI, as of May 24th, 2025.
  <br>&nbsp;&nbsp; I have the beginnings of a 'Micro-Term' memory implemented to act as a gated-attention during inference.
  <br>This, paired with automatic graph edge splitting ('Dynamic' in DGNN or DGAT) and use of geometric clustering, seems to be giving me values of a "remembered" object when it's outside of the dataset.
  <br>&nbsp;&nbsp; Hopefully leading to bodily awareness of limbs, objects outside of the field of view, and other 'long term' tensors/classifications at a temporary scale.
  <br>
  <br>It's a 4d kernel, in that it uses an ESN to train on it's own mistakes,
  <br>&nbsp;&nbsp; Basing it's decisions on prior back-propagation states/adjustments.
  <br>&nbsp;&nbsp; The beginnings of a meta-learning process, I hope!
  <br>
  <br>I'm using a method I'm calling 'Stack Crunching',
  <br>&nbsp;&nbsp; Where I agregate the time dependent weights into a "checkpoint" of sorts.
  <br>&nbsp;&nbsp; This allows the ESN to have a 'baseline' understanding of data that I can parse into with vectors calculated from tensor weights found within a quantized version of the input data.
  <br>
  <br>You can assume that the 'ESN' is not a standard 'Echo State Network' anymore.
  
  <br><br><div class="textFullRight">- May 2025</div>
</p><p class="blogEntryTagStyle">esn, memory, research</p></div><div class="aiDevPage-blogContentStyle" style="display: none;"><div class="blogEntryTitleRowStyle"><h1 class="blogEntryTitleStyle">My Training Data</h1><p class="blogEntryDateStyle">2025-02</p><p class="blogEntryReadTimeStyle">1 min read</p><p class="blogEntryAccessibilityStyle"><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Increase Font Size">+</button><button class="blogEntryAccessibilityButtonStyle procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor" title="Decrease Font Size">-</button></p></div><div class="procPagesAIDevHeaderSpacer"></div><p style="font-size: 1.2em;">
  If you couldn't tell, I'm training my AIs on my own works.
  <br>&nbsp;&nbsp; A personally made AI trained on personally made images / videos / photos / code / writing.
  <br>&nbsp;&nbsp; That means I can copyright my generations, right?
  <br>&nbsp;&nbsp;&nbsp;&nbsp; If I made every aspect of the AI &amp; training data?
  <br>
  <br>
  <div class="textFullRight">- February 2025</div>
</p><p class="blogEntryTagStyle">training, data</p></div></div></div></div></section></div><div class="procPagesInnerAfterBase procPagesInnerAfter"></div></div></div>
            </div>
            
            <!-- -- -- -- -->

            <div class="footerBarParent">
                <div id="footerBar" pages-default-class="defaultPage_footerBar" class="footerBar aiDevPage_footerBar">
                    <div class="leftFooter versionStyle">
                        <a href="https://github.com/ProcStack/pxlNav" target="_blank">[: pxlNav <span class="pxlNavVersion" versionadded="v1.0.0">v1.0.0</span> :]</a>
                    </div>
                    <div>
                    </div>
                    <div class="rightFooter">
                      <a href="https://github.com/ProcStack" target="_blank">ProcStack</a> / <a href="https://www.youtube.com/@trancorwd" target="_blank">Trancor</a> / <a href="mailto:trancor@metal-asylum.net" target="_blank">Kevin Edzenga</a><span class="squashInLowRes">; 2025</span>
                    </div>
                </div>
            </div>
        </div>
    </div>

    
    <!-- Import map to resolve bare module specifiers (e.g. "three" and "three/addons/...") in the browser.
         Adjust the version below if your project uses a different Three.js release. -->
    <script type="importmap">{
  "imports": {
    "three": "https://unpkg.com/three@0.171.0/build/three.module.js",
    "three/addons/postprocessing/": "./libs/three/",
    "three/addons/shaders/": "./libs/three/",
    "three/addons/loaders/": "./libs/three/",
    "three/addons/libs/": "./libs/three/",
    "three/addons/utils/": "./libs/three/",
    "pxlNav": "../../../../../js/pxlNav.module.js"
  }
}</script>
    <script type="module" id="pxlNavModule" src="../js/ProckStackGitio.js?v=2025-09-14"></script>




<canvas id="pxlNav-coreCanvas" height="1" width="1" class="pxlNav-coreCanvasStyle"></canvas></body></html>