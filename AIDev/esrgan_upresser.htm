<!--
// ProcStack.Github.io - 2024,2025
// By Kevin Edzenga
// Kevin@Metal-Asylum.Net
//
// --
// 
// Thanks for viewing the source code for procstack.github.io!
//   If you have any questions, feel free to reach out to me at the email above.
//
// If you'd rather see the source code on the repo -
//   https://github.com/ProcStack/procstack.github.io/tree/main/docs
//     For page content, see `./pages`
--><!DOCTYPE html><html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"> 
  <link rel="sitemap" href="https://procstack.github.io/sitemap.xml" type="application/xml">
  <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=5.0">
  <meta name="theme-color" content="#000822">
  <meta name="robots" content="index, follow, ai:json">
  <meta name="revisit-after" content="14 days">
  <meta name="fragment" content="!">
  <!-- Note : connical, description, & keywords update with page changes -->
  <link rel="canonical" href="http://localhost:3000/AIDev/esrgan_upresser.htm" id="canonicalLink">
  <meta name="description" content="AI development &amp; research by ProcStack, including work on Graph Attention Networks (GAT), Echo State Networks (ESN), and other AI structures.">
  <meta name="keywords" content="AI, Artificial Intelligence, Machine Learning, Deep Learning, Graph Attention Network, GAT, Echo State Network, ESN, Neural Networks, AI Development, ProcStack, Kevin Edzenga">
  <meta name="author" content="Kevin Edzenga">

  <!-- AI/LLM Data Discovery -->
  <meta name="robots" content="index, follow">
  <meta name="ai:data-source" content="https://procstack.github.io/bots/siteContent.json">
  <meta name="ai:data-manifest" content="https://procstack.github.io/data-manifest.json">
  <meta name="ai:content-api" content="https://procstack.github.io/bots/">
  <link rel="alternate" type="application/json" href="https://procstack.github.io/bots/AIDev_esrgan_upresser.htm.json" title="Site Content Data">
  <link rel="data-manifest" type="application/json" href="https://procstack.github.io/data-manifest.json" title="Data Sources Manifest">
  <link rel="ai-meta-spec" href="https://procstack.github.io/bots/ai-metadata-spec.html">

  <!-- The Socials -->
  <meta name="googlebot" content="index, follow, ai:json">
  <meta name="google" content="nositelinkssearchbox">
  <meta name="google" content="notranslate">
  <meta name="google" content="nositelinkssearchbox">

  <meta name="og:title" content="ESRGAN Upresser - AI Development - ProcStack">
  <meta name="og:description" content="AI development &amp; research by ProcStack, including work on Graph Attention Networks (GAT), Echo State Networks (ESN), and other AI structures.">
  <meta name="og:image" content="https://procstack.github.io/images/ProcStack_th.jpg">
  <meta name="og:url" content="http://localhost:3000/AIDev/esrgan_upresser.htm">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="ESRGAN Upresser - AI Development - ProcStack">
  <meta name="twitter:description" content="AI development &amp; research by ProcStack, including work on Graph Attention Networks (GAT), Echo State Networks (ESN), and other AI structures.">
  <meta name="twitter:image" content="https://procstack.github.io/images/ProcStack_th.jpg">
  <meta name="twitter:url" content="https://procstack.github.io">
  <meta name="twitter:domain" content="procstack.github.io">
  <meta name="twitter:label1" content="Written by">
  <meta name="twitter:data1" content="Kevin Edzenga">

  <title>ESRGAN Upresser - AI Development - ProcStack</title>
  <meta name="title" content="ESRGAN Upresser - AI Development - ProcStack">
  
  <script type="application/ld+json" id="ldjsonSchema">{
  "@context": "https://schema.org",
  "@type": "WebPage",
  "name": "ESRGAN Upresser",
  "description": "ESRGAN Upresser by ProcStack, exploring the use of Enhanced Super Resolution Generative Adversarial Networks (ESRGAN) for image upscaling.",
  "keywords": "AI, Artificial Intelligence, Machine Learning, Deep Learning, Image Processing, ESRGAN, Super Resolution, AI Development",
  "url": "https://procstack.github.io/AIDev/esrgan_upresser.htm",
  "image": "https://procstack.github.io/images/ProcStack_th.jpg",
  "author": {
    "@type": "Person",
    "name": "Kevin Edzenga",
    "alternateName": [
      "ProcStack",
      "Trancor"
    ],
    "url": "https://procstack.github.io"
  }
}</script>
  <meta name="google-site-verification" content="BiFfMHYTXO2SVuwHbCsth_IVUmyLgIpPUfEfnDPgP00">
<link type="text/css" id="procPagesStylesheet" rel="stylesheet" href="../style/ProcStackStyle.css"><link type="text/css" id="pxlNavStylesheet" rel="stylesheet" href="../style/pxlNavStyle.min.css"></head>

<!-- -- -- -- -->




<!-- Bypassing Youtube Player API for now -->
<!--   Causing pxlNav pre-processing errors -->
<!--     To be fixed through pxlNav in the future, but for now... -->
<!-- <script src="https://www.youtube.com/iframe_api" async></script> -->

<!-- -- -- -- -->

<body>
  
<!-- -- -- -- -- -- -->
<!-- SEO for Robots -- -->
<!-- -- -- -- -- -- -- -- -->
<nav aria-hidden="true" style="display:none;" role="navigation" aria-label="Site structure for crawlers">
  <a href="/Init.htm" rel="bookmark">Initialize - Welcome and Introduction</a>
  <a href="/pxlNav/Explore.htm" rel="bookmark">pxlNav Framework - 3D Navigation Technology</a>
  <a href="/MakingOf/Development.htm" rel="bookmark">Making Of - Development Process</a>
  <a href="/ProjectsLinks/procstack.github.io.htm" rel="bookmark">Projects and Repositories Portfolio</a>
  <a href="/Blog/Technical.htm" rel="bookmark">Technical Blog and Tutorials</a>
  <a href="/AboutMe/What_am_I.htm" rel="bookmark">About Kevin Edzenga - Technical Artist</a>
</nav>

  <!-- -- -- -- -->

	<div id="verbErrorConsole">
	</div>
  
<!-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -->
<!-- Primary site & `pxlPages` Implementation  -- -->
<!-- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -->
    <div id="procPagesMainBlock" class="procPagesMainBlockStyle pagesFader pagesVisOn">
        <div id="procStackGitParent" class="procStackGitParentStyle">
            <div id="procPagesNavBlock" pages-default-class="procPagesNav_defaultStyle" class="procPagesNavBlockStyle procPagesNav_aiDevStyle">
                <div id="procPagesNavHeader" class="procPagesNavHeaderStyle gpnhScreenMedia">
                  <span class="squashInLowRes">_ProcStack_</span>
                </div>
                <nav id="procPagesNav" class="procPagesNavStyle" role="navigation" aria-label="Main navigation">
                  <a href="Init.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="init" page-name="Init" aria-label="Navigate to initialization and welcome page" role="button">Init.</a>
                  <a href="pxlNav.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="pxlNav" page-name="pxlNav" aria-label="Learn about pxlNav, this site's 3D navigation framework" role="button">pxlNav</a>
                  <a href="MakingOf.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="makingOf" page-name="MakingOf" aria-label="Behind the scenes of building this site" role="button" style="display: none;">Making<span class="procPagesHideWhenThin"> Of</span>...</a>
                  <a href="ProjectsLinks.htm" class="pageLinkStyle" pxlroomname="SaltFlatsEnvironment" pxlcameraview="defaultCam" page-name="ProjectsLinks" aria-label="View my repositories and project portfolio" role="button">Projects</a>
                  <a href="Blog.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="defaultCam" page-name="Blog" aria-label="Read my technical blog posts and tutorials" role="button" style="display: none;">Blog</a>
                  <a href="AIDev.htm" class="pageLinkStyle procPagesNav_aiDevActiveStyle" pxlroomname="CampfireEnvironment" pxlcameraview="aiDev" page-name="AIDev" aria-label="Read my technical blog posts and tutorials" role="button">AI Dev</a>
                  <a href="AboutMe.htm" class="pageLinkStyle" pxlroomname="CampfireEnvironment" pxlcameraview="aboutMe" page-name="AboutMe" aria-label="Learn about me and my background" role="button"><span class="procPagesHideWhenThin">About&nbsp;</span>Me</a>
                  <span id="procPagesToggleDOM" class="procPagesToggleDOMStyle" role="group" aria-label="View mode controls">
                    <a class="pageLinkStyle pageLinkEventStyle" pageevent="ToggleDOM" pagevalue="1" role="button" tabindex="0" aria-label="Switch to full 3D environment view" title="Switch to 3D view">§</a>
                    <a class="pageLinkStyle pageLinkEventStyle" pageevent="ToggleDOM" pagevalue="0" role="button" tabindex="0" aria-label="Switch back to page content view" title="Switch to page content view" style="display: none;">¤</a>
                  </span>
                </nav>
            </div>

            <!-- -- -- -- -->
            
            <div id="pxlPagesContentBlock" class="pxlPagesContentBlockStyle gpcpVisibleStyle heightFader">
              <div id="pxlPagesContentParent" class="pxlPagesContentParentStyle"><div class="gpcpVisibleStyle procPagesContentStyle procPagesPlacementTripleStyle aiDevPageStyle pagesFader pagesVisOn"><div class="procPagesInnerBeforeBase procPagesInnerBefore"></div><div class="procPagesInnerStyle procPagesParentStyle aiDevPageParentStyle procPagesLayoutTripleStyle" id="pxlPage_AIDev"><div class="procPageHeader procPagesHeaderStyle">AI Development</div><div class="procPagesHeaderLine aiDevPage-headerLine"></div><nav role="navigation" aria-label="Page sections" class="procPageSectionList aiDevPage-sectionNavListStyle"><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to My Introduction section">My Introduction</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to ESN Motion Prediction section">ESN Motion Prediction</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to GAT &amp; Language section">GAT &amp; Language</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle procPagesNavActive aiDevPage-sectionNavButtonActiveStyle" role="button" tabindex="0" aria-label="Navigate to ESRGAN Upresser section">ESRGAN Upresser</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to GNN Exploration section">GNN Exploration</div><div class="procPagesNavSectionStyle procPagesButtonStyle procPagesSectionNavColor aiDevPage-sectionNavButtonStyle" role="button" tabindex="0" aria-label="Navigate to Notes &amp; Research section">Notes &amp; Research</div></nav><section class="procPageMediaView aiDevPageScrollbarStyle" role="region" aria-label="Media gallery for AIDev page sections" aria-describedby="Dynamic media content that changes based on selected section" style=""><div class="procPagesMediaListStyle pagesVisOff"><iframe src="https://www.youtube-nocookie.com/embed/XJu-UJrI6yk" title="Useful AI for Visual Graphics" frameborder="0" allow="encrypted-media; picture-in-picture" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="true" class="procPagesMediaStyle procPagesLimitWidthStyle"></iframe></div><div class="procPagesMediaListStyle procPagesSectionActive pagesVisOn"><video src="../pages/aiDev/images/gan_C_training_visualization_18.webm" loop="" controls="" preload="metadata" class="procPagesMediaStyle setAspectRatio_2_1"></video><div class="procPagesMediaCaptionParentStyle aiDevPage-sectionCaptionStyle"><div class="procPagesMediaCaptionStyle">Training visualization of the ESRGAN Upresser.<br>The Generator (blue) creates images,<br>The Discriminator (red) checks if the generated image is realistic.<br>As it trains, the Generator gets better at creating images.</div></div><video src="../pages/aiDev/images/gan_C_generator_evolution.webm" loop="" controls="" preload="metadata" class="procPagesMediaStyle setAspectRatio_1 setH55vh"></video><div class="procPagesMediaCaptionParentStyle aiDevPage-sectionCaptionStyle"><div class="procPagesMediaCaptionStyle">The Generator's upscaled output as it trains;<br>Training 8x8 -&gt; 32x32 resolution scaling; Running 50 epochs.</div></div></div></section><section class="procPageContentView aiDevPageScrollbarStyle" role="main" aria-label="Primary content area for AIDev page" aria-describedby="Main content that updates dynamically based on selected section navigation"><div class="procPageSectionContentStyle pagesVisOff" id="0"><div class="procPagesInnerContentStyle pagesVisOff">
    <div class="textSpacer"></div>
    <div class="procPagesAboutMe-infoStyle">
      <br>I started my dive into AI in 2008 writing a Boid / Crowd system for my thesis while in art college, School of Visual Arts.
      <br>&nbsp;&nbsp; It was an insane particle script + 3d animation cycles in Maya haha.
      <br>Then I did Boid movement, navigation, &amp; obstacle detection in animated films for 5 years at Blue Sky Studios, using Houdini.
      <br>
      <br>I dove into Style-Transfer AI &amp; Long Short-Term Memory (LSTM) training in 2019-2020,
      <br>&nbsp;&nbsp; Like making a Node.js server (web site) understand my voice &amp; auto google search for me.
      <br>
      <br>Since then, I've been developing different multi-media AI structures in my spare time.
      <br>
      <br><div class="procPagesAboutMeBar"></div>

      <br>In 2015 I decided I'd cram a machine learning AI into a single-board computer, a Jetson TK1, by the end of 2026.
      <br>&nbsp;&nbsp; Something that could write down what I say,
      <br>&nbsp;&nbsp; Use vision to understand an object simply went out of frame.
      <br>&nbsp;&nbsp;&nbsp;&nbsp; Yet "knows" if it looks over, the object is still there; 'Attention'
      <br>
      <br>At the end of 2023, this evolved into a deep learning AI crammed into, likely, a Jetson Nano.
      <br>&nbsp;&nbsp; As something to infer what I mean, from what I say,
      <br>&nbsp;&nbsp; Or give a "thought" on what it saw or heard in the world around it.
      <br>

      <br><span class="innerCenter">
        'Machine Learning' is AI that can learn basic patterns.
        <br>'Deep Learning' is Machine Learning,
        <br>But uses neural networks to form patterns of patterns.
      </span>

      <br>
      <br>Realistically, I'd just be happy to make something that can understand what I say and can give a <span class="textItalic">semi</span> coherent response without an internet connection.
      <br>
      <br>As of May 24th 2025, I've started on the core of the AI,
      <br>&nbsp;&nbsp; But still testing different structure's ability in adapting to stimuli.
      <br>&nbsp;&nbsp; ... It really seems like any network could work for most things, but some are better than others per task.
      <br>

      <br><span class="innerCenter">
        You could guess,
        <br>All the recent AI hullabaloo (2019-...)
        <br>Has been quite serendipitous for my creation!
      </span>
    </div>
  </div></div><div class="procPageSectionContentStyle pagesVisOn procPagesSectionActive" id="3"><div class="procPagesInnerContentStyle procPagesSectionActive pagesVisOn">
    <div class="textSpacer"></div>
    <div class="procPagesAboutMe-infoStyle">
      <span class="textNudge">ESRGAN Image Upresser!</span>
      <br>This was a fun one for me, I've been using ESRGANs for a while now,
      <br>&nbsp;&nbsp; And wanted to build a GAN to better understand how they work.

      <br>
      <br><span class="innerCenter">ESRGANs are a type of Generative Adversarial Network (GAN),
      <br>An 'Enhanced Super Resolution GAN' to be specific.
      <br>They are used to upscale images, making them larger and clearer.
      <br>Like in FBI shows where they enhance the security footage,
      <br>Enhance..... Enhance! .... ENHANCE!
        <div class="procPagesAboutMeSpacer"></div>
      </span>
      
      <br>
      <br>So I built an ESRGAN, more specifically a 'Real-ESRGAN',
      <br>&nbsp;&nbsp; Which is a more advanced version of the original ESRGAN.

      <div class="procPagesAboutMeSpacer"></div>

      <br>
      <br>This always seemed like magic to me,
      <br>&nbsp;&nbsp; Figuring out the associations between pixels in an image,
      <br>And then using those associations to create a larger, clearer image.

      <br>
      <br>In this video, you'll see 4 images and the 'Training Loss' or 'Discriminator Loss' graphs.
      Input Noise, Low Resolution Image, the Upresser Output, and the Original Image.
      <br>&nbsp;&nbsp; The graph shows how well the GAN is learning to generate realistic images.

      <br>
      <br>The training is being done by a Generator AI and a Discriminator AI.
      <br>The Generator creates images, and the Discriminator checks if they look like the original images.

      <br>
      <br>As the training progresses, the Generator gets better at creating realistic images,
      <br>&nbsp;&nbsp; You can see how well the AI Upress looks after just a few epochs.

      <br>
      <br>But, it takes a lot of training before it has a good understanding of the images.
      <br>Once the Generator has a reasonable understanding of the images,
      <br>And the Discriminator has a good understanding of what a real image looks like,
      <br>The two ai's begin to work together, becoming 'balanced' in their understanding.
      <br>
      <br>This is what happens at the end of the video here.
      <br>&nbsp;&nbsp; The two converge on an 'understanding' of the image,
      <br>And the Generator starts to create images that look even closer to the original image.

      <div class="procPagesAboutMeSpacer"></div>

      <br>
      <br>The biggest aspect of a GAN is the 'adversarial' part,
      <br>&nbsp;&nbsp; The Generator and Discriminator are constantly trying to outsmart each other.
      <br>The Generator tries to create images that look like the original images,
      <br>And the Discriminator tries to figure out if the images are real or fake.
      <br>
      <br>As they train, they get better and better at their tasks.

      <br><br><div class="procPagesAboutMeBar"></div>

      <br>
      <br>What's not shown here?
      <br>I implemented a 'memory supported' training method.
      
      <br>
      <br>Should confidence change too drastically for too many epochs,
      <br>&nbsp;&nbsp; Or loss increases too much too quickly,
      <br>
      <br>The training will adapt by 'remembering' the last 'good direction' of changing pixels.
      <br>&nbsp;&nbsp; Allowing the model to maintain a sense of continuity,
      <br>&nbsp;&nbsp;&nbsp;&nbsp; Even if it loses confidence in itself.

      <br>
      <br>As a result, the Generator seemed to learn faster and smoother.
      <br>&nbsp;&nbsp; If this is causing a negative effect, I'm yet to see it.
      <br>&nbsp;&nbsp; More testing is needed with larger datasets and more complex images.

      <br>
      <br>I only implemented this 'memory support' for the Generator,
      <br>&nbsp;&nbsp; As the Discriminator is more of a 'check' and doesn't need to remember past states.
      <br>&nbsp;&nbsp; Who knows, perhaps if I grow this AI further, I may need to implement a memory for the Discriminator as well.

      <br>
      <br>But it seems to be working so far!
      <br>

    </div>
  </div></div></section></div><div class="procPagesInnerAfterBase procPagesInnerAfter"></div></div></div>
            </div>
            
            <!-- -- -- -- -->

            <div class="footerBarParent">
                <div id="footerBar" pages-default-class="defaultPage_footerBar" class="footerBar aiDevPage_footerBar">
                    <div class="leftFooter versionStyle">
                        <a href="https://github.com/ProcStack/pxlNav" target="_blank">[: pxlNav <span class="pxlNavVersion" versionadded="v0.0.28-dev">v0.0.28-dev</span> :]</a>
                    </div>
                    <div>
                    </div>
                    <div class="rightFooter">
                      <a href="https://github.com/ProcStack" target="_blank">ProcStack</a> / <a href="https://www.youtube.com/@trancorwd" target="_blank">Trancor</a> / <a href="mailto:trancor@metal-asylum.net" target="_blank">Kevin Edzenga</a><span class="squashInLowRes">; 2025</span>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <canvas id="pxlNav-coreCanvas" height="600" width="800" class="pxlNav-coreCanvasStyle" data-engine="three.js r171" style="width: 800px; height: 600px;"></canvas>

    <script type="module" id="pxlNavModule" src="../js/ProckStackGitio.js?v=2025-02-08"></script>




</body></html>