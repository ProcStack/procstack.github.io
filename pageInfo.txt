ProcStack
Kevin Edzenga’s Technical Portfolio
December 2023

https://ProcStack.github.io
Page info and the what’nots


-- -- – -- -- – -- -- – -- -- – -- -- – -- -- – 
-- -- – -- -- – -- -- – -- -- – -- -- – -- -- – 
-- -- – -- -- – -- -- – -- -- – -- -- – -- -- – 


-- -- --

Go on a trip

-- -- --
Making Of

***Note*, if you want to see the shader code I'm talking about below, just hit ‘Y’ on your keyboard.
This will open the vertex and fragment shader text editor. Just pick an object from the pull down to view it's shader code.**

Initial brainstorm, make a portfolio site using the pxlNav JavaScript navigation & load it to the brim with custom shaders everywhere!
The very material & screen effects seen before you!

To come up with a scene that encompasses all the challenges of real time dev & shader design.
Like a rabbit druid poking a campfire with a stick!
**Pokey pokey stick**

To show a flame’s breath, dance, light, & shadow,
To have optimized ambient occlusion, sub surface scatter, & screen effects,
To billow that smoke & whisk those embers.

Character concepts started with MidJourney prompts for generative ai animal druids of some sort. Having tried a few animals,(You can tell I haven't needed to think about my fursona before, haha) I went for a rabbit druid character, since I have a bit too much energy and I'm speedy enough.


Mr. Rabbit Druid
Modeled, UVed, Textured, Rigged, Controlled, Weighted, Animated, Exported, Integrated…
Yay! Now, poke a barrel with a stick!

I decided, for the fun of it, to make a scatter sampler for texture baking in Houdini.  Writing a tool to scatter rays from every point on the surface of the texture to the corresponding image pixel.

Leveraging a tool I created to read point/primitive attributes to the object’s uv space,
To build images from geometry attributes in Houdini,
I added ray count and a cone of scatter to sample nearby surface distances from the world space position & normal.
I used this tool to gather ambient occlusion data and bake out surface thicknesses for sub-surface scatter.

Was it necessary? No, but now I have a ray tracer that does texture bakes in seconds.

–
Windows To The Soul
There are 2 main things which help convey life in a character to me, breathe & their gaze.
With a rigged chest for breathe, I add a look-at target object for gaze.
I'm able to animate the eyes through shaders and some vectors calculated using matrix math. This lets the eyes actually look towards what the rabbit druid is looking at.

By having an empty object in three.js as a look-at, I'm able to cast that position into each eye’s geometric space using matrix math. That may seem complicated to some out there, but is quite easy in three.js.  Simply multiplying the world space matrix of the eye by the inverted world matrix of the look-at object, you'll have a vector that can be used as an offset in the UV positions of the iris/pupil texture.

–
The Campfire
It go vvwooshhhh!  Stoke that flame buddy!
Mixing overlapping 3d noise textures, it takes on these spiky compounding wave crests,
Breathing a life into itself!

Then comes all of the stuff that's not the campfire, that's directly related to it in one specific way…


The lighting
Up for a challenge, decided to rewrite the point light object into a campfire light.  Well, more specifically, a line segment light with thickness.

This changes how the objects need to look up their positioning in that shadow map.
Having written a shadow system with options for radial or axial distorted shadows, how hard could it be to cast it to a cylinder or conical shape?

–
The Wooden Fuel
Crickle crack!

–
Smoke & Embers
Some noise in space, pushing around sprites in a delightful way!
The shader cycles the particle’s position around, varying it ever so slightly every time they shoot out.  This is happening from the particles counting their offsets based on their age and original id.
Giving rise to non-baked, organic feeling, smoke and ember systems.


–

Then just slap mr. rabbit druid into a scene with the the camp fire, some logs, a pokey stick, and what you have is a sweet bippy after that!
A scene pxlNav can understand & import the character objects, materials, lighting, and camera animation from your fbx scene.
…
Too bad that “just slap” took months of fine tuning the scene hierarchy and pipeline of pxlNav for Antibody Club in 2020.
The only update needed for this new implementation of pxlNav was a system to handle character animations and link them with the player controller & animation state machine.

So that's it. Just a quick hop leap and several weeks later, we have the first publicly available source of pxlNav.
I realize this repo is messy with all my self promotion junk.
But I will have a proper pxlNav repo open to contributions once I call these updates done.
Perhaps early January.
For the time being, you can look through the source code on this repo.

Stay creative!
-Kevin Edzenga

-- -- --

Who am I?

Eyo, I'm ProcStack, Trancor, or Kevin Edzenga
Nice to meet ya!

I like messing with computer graphics,
Plus make websites, DIY, metal/wood puzzles, & bout anything visual.

Currently my focus has been on GPU ussage.
OpenGL, GLSL, and the different shader stages.
Having been working on a project requiring an opengl engine from the ground up.
Currently the repo is set private,
But coded it through pyqt’s openGL access on qtGui.
…
Well…. Actually….
I coded the OpenGL implementation working 3 different times, 3 different ways, because I didn't know the limitations I’d hit with first Python’s OpenGL module’s interaction with PyQT, so I coded it in PyQT4’s qtOpenGL. Which I later needed to upgrade my project to PyQT5 and thus the now defunct qtOpenGL needs to be converted to the qtGui module…. so that was a fun… several weeks.
But ended up with an openGL viewport, with dynamically sourcing custom material shaders, shared context, with differed render buffers. Allowing for multiple of the pyqt widgets to display in a window at once.

You might be able to assume why "python"
With AI becoming so readily available,
I've been making a bunch of projects including ais over the years, from audio interpreters trained on my voice, to style transfer networks, to the newer stable diffusion textual inversions and loras.
While these projects have been for myself so far,
Nothing’s been made public on my github.
Maybe shortly,
But there are better ai resources out there than myself.

When life gives you lemons,
Throw em at some pigeons!
-Kevin Edzenga

–

PS. Why the two screen names?
‘Trancor’ was used on GitHub.

So you can think of ‘Trancor’ as the pre-rendered visual graphics & DIY content.
While ‘ProcStack’ is the web, coding, & real time graphics dev
With some crossover, like my Trancor ShaderToy
  Check out the Projects page for different whos’ama’whats’its and dingle bops I've made!



-- -- –
Projects/Links-

[Metal-Asylum](http://Metal-Asylum.net)
  Best on desktop
    My main site
      Changing every couple years, never quite getting to a state of being “done,” yet always a shotgun blast of different dev work.
      Currently a real time first-person cabin in the woods, well, a forest with less trees than desired.
      This is using my javascript ‘pxlNav’ camera navigation and scene interpreter system for Three.js.
      Since it's pxlNav, and like this site, if you hit ’Y’ on your keyboard, the shader editor will pop up.  Here you can look through the openGL shader code of the different object’s materials in site.


[Pixelmancer](https://pxlmancer.com)
  A full drawing/painting app on desktop,
  A fun fidget toy on mobile.
[!TV Kid timelapse](https://pxlmancer.com/show/tvKid.gif)
    A multi year project to make a full fledge drawing site with layer support, brush types, vector tools, brush effects (cpu based pixel effects, this was pre-learning about opengl shaders or webgl),
  A mixing pallet you can blend colors together to use, then save the pallet to a number key,
  All of which can be saved to a pxlm file, to maintain your layers, settings, pallet swatches, and all!
[More on Imgur](https://imgur.com/gallery/8lSW1)
[!TV was king!](https://pxlmancer.com/show/tvKid.png)
[!Cat Tax of course!](https://pxlmancer.com/show/kitty.png)


[Neurous](https://neurous.net)
  *Might be more fun on phone*
    A few day project.
    Just a page you can play around with particles.  A random project to make a custom emitter and particle class structure in javascript.

[pxlCam](https://pxlmancer.com/gl/pxlCam)
  *Use on phone!!*
    A few day project.
    A custom photo filter site with interactive color and edge effects opengl shaders, using three.js for gpu access, and your multiple phone cameras in-browser.
    Tap the triple down arrow to change the filter.  Tap and drag left & right or up & down to change the current filter’s hue & saturation or edge detection size & brightness

Repos to Check Out-
[procPromo Minecraft Shader Pack](https://github.com/ProcStack/procPromo_ShaderPack)
A shader pack written for Minecraft, used through Optifine.
For the pack, I developed depth based smart texture bluring, in attempts to capture the Minecraft Key or Promo art used when new updates are released.

This included developing a edge detection system using depths & surface nornals saved through differed buffers, where the actual edge detection is performed on a final render pass.

Having also wrote a shadow distortion & bias system as well.  Having never written a shadow shader before, or the subsequent position projections from ever shader that would sample the shadow buffer, I wrote a simple radial distortion, distance based from the player.  However there were shadow scalping everywhere.
Circular shadow projections, in a cubic game based around 90 degree angles.
I then wrote a per-axis distortion system with biasing based on distance from camera.
This allowed for sharp crisp shadow edges on blocks, but also with the distance based biasing, solved a lot of depth based issues.
Allowing me to create a shadow with little to know peter panning, little scalping, edges on surfaces parallel to the suns directional rays, all at great distances from camera.

[PxlVisualizer](https://github.com/ProcStack/pxlVisualizer)
Trippy visuals, using OpelGL and C++ through OpenFrameWorks.
Originally written in Python for PyGame, decided it would be a fun project to learn C++ on.

[pxlTextGenerator](https://github.com/ProcStack/pxlTextGenerator)
Text to handwriting generator
Created to capture the personality of one of my characters, Diece; the very one who lives in the cabin of Metal-Asylum.net.
Letting them write the very words written in the tome perched upon the desk.
A segmenter, labeler, and scripting language was written to allow saving individual characters, variants, and written pages, with text effects like opacity, scale, and kearning.

Scan some writing, click the letters, adjust the spacing, type your page with those letters, and hit save!


The One’Offs-

[ShaderToy](https://www.shadertoy.com/user/trancor)
  Only 3 at the moment.
  An exploration into the Kuwahara Filter being used in a single pass smart blur & edge detection.
  A Ray Marching shader to learn about sdf math.
  And 0-1 blending & animation helper functions with animated nyans, rainbows, and stars!

[Dwitter](https://dwitter.net/u/trancor)
  JavaScript code golfing
  When all you get is 140 characters,
    Better make em count!
  

Socials-

[YouTube](https://www.youtube.com/@trancorwd)
[Instagram](https://instagram.com/trancor.diy)
[GitHub (you're there baby!)](https://github.com/ProcStack)







-- -- --
Skills / Career

My Shtick?
Curiosity hasn't killed this cat yet!

My Joy?
I focus on asset real time prep & integration; with an interest in pipeline tooling.


(#, is years of use with, not all professionally, but you can assume <4 is on the job.)

Software -
Houdini(16), Maya(19), Photoshop(25+, maybe 30+, can't remember, my mom had it around the house for work, it was fun messing with!), Unity(4), Three.js(5), Touch Designer(3), After Effects(19), Arduino(9), Cura(7), SparkAR(3), Lens Studio(3), Unreal Engine(1, mostly network layer & player controller blueprint/c++)
With working knowledge of Substance
Painter/Designer, Nuke, Cinema4D, & Notch.
Stumbling knowledge of Blender, Godot, & O3de.


Languages -
Python(16), Maya's MEL(17), Houdini's VEX(14),
OpenGL(2) & ES(5) (Proficient with GLSL, differed pipelines, & warp/wavefront needs; however, only limited C++ & Python OpenGL integration with shared contexts),
Unity's ShaderLabs(4) (Based on HLSL)
Javascript(25-28, started with GeoCities, my first script was an image gallery of dragon ball z characters & show screen grabs) (Mostly Front end, some Back, and a little Middle; Native & Node.js; Three.js(5), WebSocket(4), WebRTC(3), Redis(1), Express(3), View Engine(1), Sessions/SQL/Mongo(1)), HTML/CSS(27-29, back when search engines indexed sites by hand, and you were able to ask a Jeeves!), Terminal/Bash/Shell/DOS(33?, I dunno, when do kids become sentient? Like 4-5? So maybe 33 years for me?  All we had was DOS back when. But computers had cool names since clock speeds were so slow, like ‘333’, ‘686’, or ‘888’, with turbo buttons to overclock the PC on the fly, it was sick!  The sound of an old computer booting up is the best sound in the world to me.)


Pipeline / Environments -
GitHub, Jira, Slack, Discord, GitLabs, Perforce/SVN/CVN, Confluence, Shotgun, Nginx, Plesk, AWS, Windows / Linux(Fedora, CentOS, Debian, Ubuntu; xcfe & gnome) / iOS 


Hardware -
Mobile/Arm/SoC Dev (iOS or Android; Unity, SparkAR, & Lens Studio; with android studio & xcode; mostly Mali & Adreno gpus), Oculus 2, Holo Lens, Arduino (module & attiny chips), STM32, Raspberry Pi

Accomplishments -
2 publications including work I did while at Blue Sky Studios. In 2015 for camera locked crowd navigation and joint animation for the animated film ‘Peanuts’
[You've got a lot of friends, Charlie Brown: creating crowds in peanuts](https://dl.acm.org/doi/10.1145/2775280.2792517)
The other in 2017 for joint/hierarchy control through neck joint look-at, assisted in a horse’n’jockey crowd system, and wrote how riders joints could be controlled by the vehicle they are in.
[Populating the crowds in Ferdinand](https://dl.acm.org/citation.cfm?id=3085055)


Quirks -
When left to research or proofing concepts, I have a penchant for exploring all of the possible options.
A bit of a termite mound of a focus pattern on me here.
But I keep a sticky note of two dots with a line drawn between them stuck to my monitor.
Making sure to keep a daily todo check list to combat exploritory research.
So check-ins are never a bother!

I operate best in social environments, with a morning daily stand up and mid-afternoon hand in to allow for things not working, desk-sides, meetings, and late hand-ins.
Allowing time to review before morning dailies.
When you plan for a 4pm, it gives room for the inevitable 5 and 6pms…

Known-knowns always help the situation.
When we have a label to give something, means we can be cognizant of that!
So being forward and discussing issues openly helps quell any future snafus.


Skills / Hobbies -
DIY of which ever kind, from wall hanging led lamps to a wooden foot rest with springs and padding, to bracelets & this sling bag I'm starting on my 4th redesign of.
Sewing, Writing, Raving/Dancing, Chainmaille, Juggling (Only 3 things… Not 2, not 4, only 3... 4 is hard, unless I have plenty of head room!)


Schooling -
School of Visual Arts, NYC; BFA, class of 2009
With classes in Maya, Houdini, Photoshop, After Effects, Python/Mel


Carrer History - **(Newest to oldest)**
-Remote Control Media - 1 year 10 Months (contracts)
-GenXP - 7 months (contract)
-The Umbrella NYC - 9 months (project)
	Antib0dy.Club
		Head Code Monkey / CTO
			Fullstack JavaScript, Jitsi/webRTC, Nginx, AWS
		A virtual event space with live streaming djs, web cam personal avitars with spacial audio using your mic.
		This was the origin of `pxlNav`, the camera, player controller, collision detection, render stack, multi-player avatar support, items/pick-ups, portals, and a fbx scene structure which automatically builds the `pxlNav` scene/environment.
		I was the lead developer, having written well over 20k lines of javascript for the entire website/server/network stack. Working with Error404's core event team and party promoters; later we got 3 more web devs to help on-and-off in certain areas.
-BUCK (NYC) - 1 year 2 months (contracts)
   Technical Artist
-Blue Sky Studios - 8 years 7 months (employed)
  Bounced between 3 different departments during my time there,

	  Character Simulation TD, ~3 years
		  Rio 1, Epic, Rio 2 (some)
			  Clothing & Hair simulation, nCloth & Qualoth, some pipelines/render prep tools in Maya

		FX TD, ~1 year
		  Ice Age 4
				Houdini mostly, with some Maya; Particle/instancing sims, RBDs, Smoke/Dust Volume sims, Ocean foam

		Crowds TD, ~5 years
		  Rio 2, Ice Age 5, Peanuts, Ferdinand, Spies In Disguise
				When we first started, we were instancing birds into Maya onto particles. When I left, well, we were still loading instances in Maya, but mostly to help other departments.
				I was part of the department’s formation, and we built an entire suite of crowd placement, navigation, rendering, management, and review tools between Houdini, Maya, and our in-house renderer.
				I developed foot locking, quad terrain adapting ik, navigational systems with obstacle avoidance, placement tools, and navigational flow using concepts similar to Navier-Stokes to path find by vector field, rather than other stricter path finding methods.
				While on the team, we were acknowledged twice by the Siggraph board. Allowing me the pleasure of speaking at Siggraph.
				Some of my fondest accomplishments is an automatic look-at with multi-joint necks.  This was used more in Ice Age 5 for these long necked characters, to actually bend their neck and look at things around them.  Also part of the horse’n’jockey system I assisted with on Ferdinand, and our second Siggraph acknowledgement. Where the driver’s hands adapt with IK to the steering wheel, as the parent agent (the car) is driving.
				After a while, a couple of us branched our pipeline out to storyboard/layout.  I wrote a series of placement and agent tweaking tools to utilize our light weight crowd agents in Maya. This was a help in visualizing the director's concepts quicker.

-- -- --
-- -- --
Contact Me


